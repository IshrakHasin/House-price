{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  import sys\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "test_index=test.shape[0]\n",
    "train_index=train.shape[0]\n",
    "train_ID = train['Id']\n",
    "test_ID = test['Id']\n",
    "train.drop(\"Id\", axis = 1, inplace = True)\n",
    "test.drop(\"Id\", axis = 1, inplace = True)\n",
    "train_raw_labels = train['SalePrice'].to_frame().as_matrix()\n",
    "train_labels=train['SalePrice'].values\n",
    "concated_dataset=pd.concat([train,test])\n",
    "concated_dataset.drop(['SalePrice'], axis=1, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1459, 79)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 1)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_raw_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>Alley</th>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <th>BldgType</th>\n",
       "      <th>BsmtCond</th>\n",
       "      <th>BsmtExposure</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>...</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>Street</th>\n",
       "      <th>TotRmsAbvGrd</th>\n",
       "      <th>TotalBsmtSF</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>WoodDeckSF</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>YrSold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>856</td>\n",
       "      <td>854</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>TA</td>\n",
       "      <td>No</td>\n",
       "      <td>706.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>WD</td>\n",
       "      <td>0</td>\n",
       "      <td>Pave</td>\n",
       "      <td>8</td>\n",
       "      <td>856.0</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>0</td>\n",
       "      <td>2003</td>\n",
       "      <td>2003</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1262</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>TA</td>\n",
       "      <td>Gd</td>\n",
       "      <td>978.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>WD</td>\n",
       "      <td>0</td>\n",
       "      <td>Pave</td>\n",
       "      <td>6</td>\n",
       "      <td>1262.0</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>298</td>\n",
       "      <td>1976</td>\n",
       "      <td>1976</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>920</td>\n",
       "      <td>866</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>TA</td>\n",
       "      <td>Mn</td>\n",
       "      <td>486.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>WD</td>\n",
       "      <td>0</td>\n",
       "      <td>Pave</td>\n",
       "      <td>6</td>\n",
       "      <td>920.0</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>0</td>\n",
       "      <td>2001</td>\n",
       "      <td>2002</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>961</td>\n",
       "      <td>756</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>Gd</td>\n",
       "      <td>No</td>\n",
       "      <td>216.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>WD</td>\n",
       "      <td>0</td>\n",
       "      <td>Pave</td>\n",
       "      <td>7</td>\n",
       "      <td>756.0</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>0</td>\n",
       "      <td>1915</td>\n",
       "      <td>1970</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1145</td>\n",
       "      <td>1053</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>TA</td>\n",
       "      <td>Av</td>\n",
       "      <td>655.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>WD</td>\n",
       "      <td>0</td>\n",
       "      <td>Pave</td>\n",
       "      <td>9</td>\n",
       "      <td>1145.0</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>192</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   1stFlrSF  2ndFlrSF  3SsnPorch Alley  BedroomAbvGr BldgType BsmtCond  \\\n",
       "0       856       854          0   NaN             3     1Fam       TA   \n",
       "1      1262         0          0   NaN             3     1Fam       TA   \n",
       "2       920       866          0   NaN             3     1Fam       TA   \n",
       "3       961       756          0   NaN             3     1Fam       Gd   \n",
       "4      1145      1053          0   NaN             4     1Fam       TA   \n",
       "\n",
       "  BsmtExposure  BsmtFinSF1  BsmtFinSF2  ...   SaleType ScreenPorch  Street  \\\n",
       "0           No       706.0         0.0  ...         WD           0    Pave   \n",
       "1           Gd       978.0         0.0  ...         WD           0    Pave   \n",
       "2           Mn       486.0         0.0  ...         WD           0    Pave   \n",
       "3           No       216.0         0.0  ...         WD           0    Pave   \n",
       "4           Av       655.0         0.0  ...         WD           0    Pave   \n",
       "\n",
       "   TotRmsAbvGrd TotalBsmtSF  Utilities WoodDeckSF YearBuilt YearRemodAdd  \\\n",
       "0             8       856.0     AllPub          0      2003         2003   \n",
       "1             6      1262.0     AllPub        298      1976         1976   \n",
       "2             6       920.0     AllPub          0      2001         2002   \n",
       "3             7       756.0     AllPub          0      1915         1970   \n",
       "4             9      1145.0     AllPub        192      2000         2000   \n",
       "\n",
       "  YrSold  \n",
       "0   2008  \n",
       "1   2007  \n",
       "2   2008  \n",
       "3   2006  \n",
       "4   2008  \n",
       "\n",
       "[5 rows x 79 columns]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concated_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Missing Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PoolQC</th>\n",
       "      <td>99.657417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MiscFeature</th>\n",
       "      <td>96.402878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alley</th>\n",
       "      <td>93.216855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fence</th>\n",
       "      <td>80.438506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FireplaceQu</th>\n",
       "      <td>48.646797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LotFrontage</th>\n",
       "      <td>16.649538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GarageQual</th>\n",
       "      <td>5.447071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GarageCond</th>\n",
       "      <td>5.447071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GarageFinish</th>\n",
       "      <td>5.447071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GarageYrBlt</th>\n",
       "      <td>5.447071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GarageType</th>\n",
       "      <td>5.378554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtExposure</th>\n",
       "      <td>2.809181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtCond</th>\n",
       "      <td>2.809181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtQual</th>\n",
       "      <td>2.774923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtFinType2</th>\n",
       "      <td>2.740665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtFinType1</th>\n",
       "      <td>2.706406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MasVnrType</th>\n",
       "      <td>0.822199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MasVnrArea</th>\n",
       "      <td>0.787941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSZoning</th>\n",
       "      <td>0.137033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtFullBath</th>\n",
       "      <td>0.068517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtHalfBath</th>\n",
       "      <td>0.068517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Utilities</th>\n",
       "      <td>0.068517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Functional</th>\n",
       "      <td>0.068517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Electrical</th>\n",
       "      <td>0.034258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <td>0.034258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Exterior1st</th>\n",
       "      <td>0.034258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Exterior2nd</th>\n",
       "      <td>0.034258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TotalBsmtSF</th>\n",
       "      <td>0.034258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GarageArea</th>\n",
       "      <td>0.034258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GarageCars</th>\n",
       "      <td>0.034258</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Missing Ratio\n",
       "PoolQC            99.657417\n",
       "MiscFeature       96.402878\n",
       "Alley             93.216855\n",
       "Fence             80.438506\n",
       "FireplaceQu       48.646797\n",
       "LotFrontage       16.649538\n",
       "GarageQual         5.447071\n",
       "GarageCond         5.447071\n",
       "GarageFinish       5.447071\n",
       "GarageYrBlt        5.447071\n",
       "GarageType         5.378554\n",
       "BsmtExposure       2.809181\n",
       "BsmtCond           2.809181\n",
       "BsmtQual           2.774923\n",
       "BsmtFinType2       2.740665\n",
       "BsmtFinType1       2.706406\n",
       "MasVnrType         0.822199\n",
       "MasVnrArea         0.787941\n",
       "MSZoning           0.137033\n",
       "BsmtFullBath       0.068517\n",
       "BsmtHalfBath       0.068517\n",
       "Utilities          0.068517\n",
       "Functional         0.068517\n",
       "Electrical         0.034258\n",
       "BsmtUnfSF          0.034258\n",
       "Exterior1st        0.034258\n",
       "Exterior2nd        0.034258\n",
       "TotalBsmtSF        0.034258\n",
       "GarageArea         0.034258\n",
       "GarageCars         0.034258"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data_na = (concated_dataset.isnull().sum() / len(concated_dataset)) * 100\n",
    "all_data_na = all_data_na.drop(all_data_na[all_data_na == 0].index).sort_values(ascending=False)[:30]\n",
    "missing_data = pd.DataFrame({'Missing Ratio' :all_data_na})\n",
    "missing_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the list we can begin working with data filling.First let check what is PoolQC and why this is empthy.This have four values Ex=Excellent,Gd=Good,TA=typical,Fa=Fair,NA=no pool.So may be missing data should be NA.Lets also help our model by just replacing with neumerical values I will give Ex=4 and No Pool=0. Since the saleprice should be higher if the PoolQC is more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "concated_dataset[\"PoolQC\"] = concated_dataset[\"PoolQC\"].fillna(0)\n",
    "concated_dataset[\"PoolQC\"] =concated_dataset[\"PoolQC\"].replace(to_replace={\"Ex\": 4, \"Gd\":3,\"TA\":2,\"Fa\":1})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets verify "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "1\n",
      "3\n",
      "4\n",
      "3\n",
      "1\n",
      "3\n",
      "4\n",
      "4\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "for i in concated_dataset[\"PoolQC\"] :\n",
    "    if i !=0:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now this looks good. Now we can investigate next feature. Which MiscFeature is 96% missing data.This has Elev {Elevator}, Gar2 {2nd Garage} ,Othr {Other},Shed {Shed (over 100 SF}TenC {Tennis Court},NA   {None} values.But we can but keep NA lets replace. We also need to make it catagorical at some point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "concated_dataset[\"MiscFeature\"] = concated_dataset[\"MiscFeature\"].fillna(\"None\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "concated_dataset[\"MiscFeature\"]=pd.Categorical(concated_dataset[\"MiscFeature\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfDummies1 = pd.get_dummies(concated_dataset[\"MiscFeature\"], prefix = 'MiscFeature')\n",
    "concated_dataset = pd.concat([concated_dataset, dfDummies1], axis=1)\n",
    "concated_dataset = concated_dataset.drop(['MiscFeature'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "lbl = LabelEncoder() \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets fill up Alley.This can be of 3 types Gravel, paved and No Alley which means NA will have different meaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "concated_dataset[\"Alley\"] = concated_dataset[\"Alley\"].fillna(\"None\")\n",
    "concated_dataset[\"Alley\"] =concated_dataset[\"Alley\"].replace(to_replace={\"Grvl\": 2, \"Pave\":1,\"None\":0})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "for i in concated_dataset[\"Alley\"] :\n",
    "    if i !=0:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "concated_dataset[\"Fence\"] = concated_dataset[\"Fence\"].fillna(\"None\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "concated_dataset[\"Fence\"] =pd.Categorical(concated_dataset[\"Fence\"])\n",
    "dfDummies2 = pd.get_dummies(concated_dataset[\"Fence\"], prefix = 'Fence')\n",
    "concated_dataset = pd.concat([concated_dataset, dfDummies2], axis=1)\n",
    "concated_dataset = concated_dataset.drop(['Fence'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets find out how to encode fireplace. From the descreption \n",
    "   Ex   Excellent - Exceptional Masonry Fireplace\n",
    "   Gd   Good - Masonry Fireplace in main level\n",
    "   TA   Average - Prefabricated Fireplace in main living area or Masonry Fireplace in basement\n",
    "   Fa   Fair - Prefabricated Fireplace in basement\n",
    "   Po   Poor - Ben Franklin Stove\n",
    "   NA   No Fireplace\n",
    "So we can replace Ex with 5 and NA with 0.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "concated_dataset[\"FireplaceQu\"] = concated_dataset[\"FireplaceQu\"].fillna(\"None\")\n",
    "concated_dataset[\"FireplaceQu\"] =concated_dataset[\"FireplaceQu\"].replace(to_replace={\"Ex\": 5, \"Gd\":4,\"TA\":3,\"Fa\":2,\"Po\":1,\"None\":0})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "3\n",
      "4\n",
      "3\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "2\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "5\n",
      "4\n",
      "4\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "4\n",
      "3\n",
      "4\n",
      "4\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "3\n",
      "2\n",
      "1\n",
      "3\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "2\n",
      "4\n",
      "3\n",
      "3\n",
      "4\n",
      "2\n",
      "3\n",
      "1\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "3\n",
      "4\n",
      "4\n",
      "3\n",
      "4\n",
      "4\n",
      "3\n",
      "3\n",
      "4\n",
      "3\n",
      "3\n",
      "4\n",
      "5\n",
      "4\n",
      "2\n",
      "4\n",
      "3\n",
      "1\n",
      "4\n",
      "3\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "5\n",
      "3\n",
      "2\n",
      "3\n",
      "3\n",
      "1\n",
      "3\n",
      "4\n",
      "3\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "3\n",
      "4\n",
      "3\n",
      "3\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "2\n",
      "4\n",
      "3\n",
      "4\n",
      "4\n",
      "5\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "4\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "3\n",
      "5\n",
      "3\n",
      "5\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "4\n",
      "3\n",
      "3\n",
      "4\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "4\n",
      "4\n",
      "5\n",
      "4\n",
      "4\n",
      "5\n",
      "4\n",
      "3\n",
      "4\n",
      "1\n",
      "3\n",
      "3\n",
      "5\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "5\n",
      "3\n",
      "4\n",
      "4\n",
      "2\n",
      "3\n",
      "2\n",
      "5\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "3\n",
      "4\n",
      "2\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "4\n",
      "4\n",
      "3\n",
      "4\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "3\n",
      "1\n",
      "4\n",
      "3\n",
      "1\n",
      "4\n",
      "4\n",
      "4\n",
      "5\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "4\n",
      "4\n",
      "3\n",
      "2\n",
      "4\n",
      "3\n",
      "2\n",
      "3\n",
      "4\n",
      "3\n",
      "4\n",
      "4\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "3\n",
      "4\n",
      "3\n",
      "2\n",
      "1\n",
      "4\n",
      "2\n",
      "3\n",
      "4\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "3\n",
      "4\n",
      "4\n",
      "3\n",
      "4\n",
      "4\n",
      "3\n",
      "3\n",
      "4\n",
      "2\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "4\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "3\n",
      "3\n",
      "2\n",
      "4\n",
      "5\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "3\n",
      "4\n",
      "3\n",
      "1\n",
      "4\n",
      "4\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "3\n",
      "4\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "5\n",
      "3\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "3\n",
      "3\n",
      "4\n",
      "3\n",
      "4\n",
      "3\n",
      "4\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "3\n",
      "5\n",
      "4\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "1\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "2\n",
      "3\n",
      "1\n",
      "3\n",
      "4\n",
      "4\n",
      "3\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "3\n",
      "4\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "4\n",
      "4\n",
      "3\n",
      "4\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "3\n",
      "4\n",
      "4\n",
      "3\n",
      "4\n",
      "2\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "4\n",
      "3\n",
      "1\n",
      "4\n",
      "3\n",
      "3\n",
      "2\n",
      "4\n",
      "3\n",
      "3\n",
      "4\n",
      "2\n",
      "4\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "1\n",
      "3\n",
      "4\n",
      "3\n",
      "4\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "3\n",
      "4\n",
      "2\n",
      "3\n",
      "4\n",
      "4\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "3\n",
      "4\n",
      "3\n",
      "4\n",
      "3\n",
      "3\n",
      "1\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "3\n",
      "4\n",
      "2\n",
      "4\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "4\n",
      "4\n",
      "3\n",
      "4\n",
      "3\n",
      "5\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "3\n",
      "4\n",
      "5\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "5\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "4\n",
      "3\n",
      "4\n",
      "4\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "1\n",
      "3\n",
      "4\n",
      "3\n",
      "4\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "2\n",
      "3\n",
      "3\n",
      "4\n",
      "3\n",
      "4\n",
      "3\n",
      "4\n",
      "4\n",
      "3\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "3\n",
      "4\n",
      "3\n",
      "3\n",
      "4\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "2\n",
      "4\n",
      "4\n",
      "3\n",
      "3\n",
      "4\n",
      "1\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "1\n",
      "3\n",
      "4\n",
      "4\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "4\n",
      "3\n",
      "2\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "1\n",
      "2\n",
      "3\n",
      "3\n",
      "4\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "4\n",
      "4\n",
      "3\n",
      "4\n",
      "4\n",
      "3\n",
      "4\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "4\n",
      "4\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "5\n",
      "4\n",
      "4\n",
      "3\n",
      "4\n",
      "3\n",
      "4\n",
      "3\n",
      "5\n",
      "4\n",
      "3\n",
      "5\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "4\n",
      "3\n",
      "4\n",
      "5\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "3\n",
      "4\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "2\n",
      "4\n",
      "5\n",
      "3\n",
      "3\n",
      "2\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "1\n",
      "3\n",
      "4\n",
      "4\n",
      "3\n",
      "4\n",
      "4\n",
      "3\n",
      "4\n",
      "4\n",
      "3\n",
      "4\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "2\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "3\n",
      "4\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "4\n",
      "3\n",
      "5\n",
      "4\n",
      "3\n",
      "4\n",
      "3\n",
      "3\n",
      "4\n",
      "3\n",
      "4\n",
      "3\n",
      "4\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "5\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "4\n",
      "4\n",
      "2\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "3\n",
      "4\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "2\n",
      "4\n",
      "4\n",
      "3\n",
      "4\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "3\n",
      "4\n",
      "3\n",
      "2\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "3\n",
      "2\n",
      "3\n",
      "3\n",
      "4\n",
      "1\n",
      "3\n",
      "2\n",
      "4\n",
      "3\n",
      "4\n",
      "3\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "5\n",
      "3\n",
      "4\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "5\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "3\n",
      "4\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "3\n",
      "2\n",
      "3\n",
      "3\n",
      "4\n",
      "1\n",
      "4\n",
      "4\n",
      "3\n",
      "4\n",
      "3\n",
      "1\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "1\n",
      "4\n",
      "2\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "1\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "1\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "3\n",
      "4\n",
      "3\n",
      "4\n",
      "4\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "3\n",
      "3\n",
      "2\n",
      "5\n",
      "3\n",
      "2\n",
      "4\n",
      "1\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "5\n",
      "2\n",
      "3\n",
      "1\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "5\n",
      "4\n",
      "4\n",
      "5\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "5\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "2\n",
      "4\n",
      "4\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "4\n",
      "3\n",
      "4\n",
      "2\n",
      "4\n",
      "3\n",
      "4\n",
      "3\n",
      "4\n",
      "1\n",
      "4\n",
      "1\n",
      "4\n",
      "4\n",
      "2\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "2\n",
      "1\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "2\n",
      "4\n",
      "3\n",
      "2\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "3\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "1\n",
      "4\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "3\n",
      "2\n",
      "3\n",
      "4\n",
      "4\n",
      "3\n",
      "1\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "5\n",
      "4\n",
      "4\n",
      "4\n",
      "5\n",
      "5\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "5\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "4\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "3\n",
      "4\n",
      "3\n",
      "4\n",
      "3\n",
      "4\n",
      "1\n",
      "3\n",
      "3\n",
      "4\n",
      "2\n",
      "4\n",
      "3\n",
      "2\n",
      "3\n",
      "4\n",
      "3\n",
      "4\n",
      "3\n",
      "4\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "2\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "1\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "4\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "4\n",
      "4\n",
      "3\n",
      "1\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "1\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "2\n",
      "3\n",
      "2\n",
      "3\n",
      "2\n",
      "2\n",
      "3\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "2\n",
      "4\n",
      "2\n",
      "4\n",
      "4\n",
      "2\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "4\n",
      "3\n",
      "3\n",
      "4\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "1\n",
      "4\n",
      "4\n",
      "3\n",
      "1\n",
      "3\n",
      "4\n",
      "4\n",
      "5\n",
      "3\n",
      "4\n",
      "4\n",
      "2\n",
      "3\n",
      "3\n",
      "4\n",
      "3\n",
      "3\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "3\n",
      "4\n",
      "5\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "3\n",
      "2\n",
      "5\n",
      "3\n",
      "2\n",
      "1\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "3\n",
      "4\n",
      "3\n",
      "5\n",
      "3\n",
      "3\n",
      "5\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "1\n",
      "3\n",
      "3\n",
      "4\n",
      "3\n",
      "3\n",
      "2\n",
      "3\n",
      "4\n",
      "1\n",
      "2\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "4\n",
      "3\n",
      "4\n",
      "4\n",
      "3\n",
      "1\n",
      "4\n",
      "4\n",
      "3\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "2\n",
      "4\n",
      "4\n",
      "3\n",
      "4\n",
      "3\n",
      "4\n",
      "4\n",
      "2\n",
      "5\n",
      "3\n",
      "4\n",
      "4\n",
      "1\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "5\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "for i in concated_dataset[\"FireplaceQu\"] :\n",
    "    if i !=0:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LotFrontage: Linear feet of street connected to property.NA probably means not given. LotFrontage : Since the area of each street connected to the house property most likely have a similar area to other houses in its neighborhood , we can fill in missing values by the median LotFrontage of the neighborhood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "concated_dataset[\"LotFrontage\"] = concated_dataset.groupby(\"Neighborhood\")[\"LotFrontage\"].transform(lambda x: x.fillna(x.median()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        65.0\n",
      "1        80.0\n",
      "2        68.0\n",
      "3        60.0\n",
      "4        84.0\n",
      "5        85.0\n",
      "6        75.0\n",
      "7        80.0\n",
      "8        51.0\n",
      "9        50.0\n",
      "10       70.0\n",
      "11       85.0\n",
      "12       72.0\n",
      "13       91.0\n",
      "14       73.0\n",
      "15       51.0\n",
      "16       73.0\n",
      "17       72.0\n",
      "18       66.0\n",
      "19       70.0\n",
      "20      101.0\n",
      "21       57.0\n",
      "22       75.0\n",
      "23       44.0\n",
      "24       72.0\n",
      "25      110.0\n",
      "26       60.0\n",
      "27       98.0\n",
      "28       47.0\n",
      "29       60.0\n",
      "        ...  \n",
      "1429     50.0\n",
      "1430     75.0\n",
      "1431     69.0\n",
      "1432     50.0\n",
      "1433     60.0\n",
      "1434     41.0\n",
      "1435     44.0\n",
      "1436     69.0\n",
      "1437     65.0\n",
      "1438     70.0\n",
      "1439    140.0\n",
      "1440     82.0\n",
      "1441     82.0\n",
      "1442     95.0\n",
      "1443     88.0\n",
      "1444    125.0\n",
      "1445     78.0\n",
      "1446     41.0\n",
      "1447     58.0\n",
      "1448     74.0\n",
      "1449     21.0\n",
      "1450     21.0\n",
      "1451     80.0\n",
      "1452     21.0\n",
      "1453     21.0\n",
      "1454     21.0\n",
      "1455     21.0\n",
      "1456    160.0\n",
      "1457     62.0\n",
      "1458     74.0\n",
      "Name: LotFrontage, Length: 2919, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(concated_dataset[\"LotFrontage\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GarageType, GarageFinish, GarageQual, GarageCond is NA if no Garage is there. NA should be replaced with None."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ('GarageType', 'GarageFinish', 'GarageQual', 'GarageCond'):\n",
    "    concated_dataset[col] = concated_dataset[col].fillna('None')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like previous I will fill up manually since this will help the netwok to tune easily. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "concated_dataset[\"GarageFinish\"] =concated_dataset[\"GarageFinish\"].replace(to_replace={\"Fin\": 3, \"RFn\":2,\"Unf\":1,\"None\":0})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       2\n",
      "1       2\n",
      "2       2\n",
      "3       1\n",
      "4       2\n",
      "5       1\n",
      "6       2\n",
      "7       2\n",
      "8       1\n",
      "9       2\n",
      "10      1\n",
      "11      3\n",
      "12      1\n",
      "13      2\n",
      "14      2\n",
      "15      1\n",
      "16      3\n",
      "17      1\n",
      "18      1\n",
      "19      1\n",
      "20      2\n",
      "21      1\n",
      "22      2\n",
      "23      1\n",
      "24      1\n",
      "25      2\n",
      "26      1\n",
      "27      2\n",
      "28      2\n",
      "29      1\n",
      "       ..\n",
      "1429    1\n",
      "1430    1\n",
      "1431    0\n",
      "1432    0\n",
      "1433    0\n",
      "1434    3\n",
      "1435    3\n",
      "1436    3\n",
      "1437    1\n",
      "1438    2\n",
      "1439    1\n",
      "1440    1\n",
      "1441    1\n",
      "1442    3\n",
      "1443    3\n",
      "1444    1\n",
      "1445    3\n",
      "1446    2\n",
      "1447    2\n",
      "1448    1\n",
      "1449    0\n",
      "1450    1\n",
      "1451    2\n",
      "1452    1\n",
      "1453    0\n",
      "1454    0\n",
      "1455    1\n",
      "1456    1\n",
      "1457    0\n",
      "1458    3\n",
      "Name: GarageFinish, Length: 2919, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(concated_dataset[\"GarageFinish\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "concated_dataset[\"GarageQual\"] =concated_dataset[\"GarageQual\"].replace(to_replace={\"Ex\": 5, \"Gd\":4,\"TA\":3,\"Fa\":2,\"Po\":1,\"None\":0})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "concated_dataset[\"GarageCond\"] =concated_dataset[\"GarageCond\"].replace(to_replace={\"Ex\": 5, \"Gd\":4,\"TA\":3,\"Fa\":2,\"Po\":1,\"None\":0})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       3\n",
      "1       3\n",
      "2       3\n",
      "3       3\n",
      "4       3\n",
      "5       3\n",
      "6       3\n",
      "7       3\n",
      "8       2\n",
      "9       4\n",
      "10      3\n",
      "11      3\n",
      "12      3\n",
      "13      3\n",
      "14      3\n",
      "15      3\n",
      "16      3\n",
      "17      3\n",
      "18      3\n",
      "19      3\n",
      "20      3\n",
      "21      3\n",
      "22      3\n",
      "23      3\n",
      "24      3\n",
      "25      3\n",
      "26      3\n",
      "27      3\n",
      "28      3\n",
      "29      2\n",
      "       ..\n",
      "1429    3\n",
      "1430    3\n",
      "1431    0\n",
      "1432    0\n",
      "1433    0\n",
      "1434    3\n",
      "1435    3\n",
      "1436    3\n",
      "1437    3\n",
      "1438    3\n",
      "1439    3\n",
      "1440    3\n",
      "1441    3\n",
      "1442    3\n",
      "1443    3\n",
      "1444    2\n",
      "1445    3\n",
      "1446    3\n",
      "1447    3\n",
      "1448    3\n",
      "1449    0\n",
      "1450    3\n",
      "1451    3\n",
      "1452    3\n",
      "1453    0\n",
      "1454    0\n",
      "1455    3\n",
      "1456    3\n",
      "1457    0\n",
      "1458    3\n",
      "Name: GarageQual, Length: 2919, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(concated_dataset[\"GarageQual\"] )"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "GarageType: Garage location. I can not impose prior to this attribute.Since from description:\n",
    "   2Types More than one type of garage\n",
    "   Attchd  Attached to home\n",
    "   Basment Basement Garage\n",
    "   BuiltIn Built-In (Garage part of house - typically has room above garage)\n",
    "   CarPort Car Port\n",
    "   Detchd  Detached from home\n",
    "   NA  No Garage\n",
    "Lets try one hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "concated_dataset[\"GarageType\"]=pd.Categorical(concated_dataset[\"GarageType\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfDummies = pd.get_dummies(concated_dataset[\"GarageType\"], prefix = 'GarageType')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "concated_dataset = pd.concat([concated_dataset, dfDummies], axis=1)\n",
    "concated_dataset = concated_dataset.drop(['GarageType'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>Alley</th>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <th>BldgType</th>\n",
       "      <th>BsmtCond</th>\n",
       "      <th>BsmtExposure</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>...</th>\n",
       "      <th>Fence_MnPrv</th>\n",
       "      <th>Fence_MnWw</th>\n",
       "      <th>Fence_None</th>\n",
       "      <th>GarageType_2Types</th>\n",
       "      <th>GarageType_Attchd</th>\n",
       "      <th>GarageType_Basment</th>\n",
       "      <th>GarageType_BuiltIn</th>\n",
       "      <th>GarageType_CarPort</th>\n",
       "      <th>GarageType_Detchd</th>\n",
       "      <th>GarageType_None</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>856</td>\n",
       "      <td>854</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>TA</td>\n",
       "      <td>No</td>\n",
       "      <td>706.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1262</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>TA</td>\n",
       "      <td>Gd</td>\n",
       "      <td>978.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>920</td>\n",
       "      <td>866</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>TA</td>\n",
       "      <td>Mn</td>\n",
       "      <td>486.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>961</td>\n",
       "      <td>756</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>Gd</td>\n",
       "      <td>No</td>\n",
       "      <td>216.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1145</td>\n",
       "      <td>1053</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>TA</td>\n",
       "      <td>Av</td>\n",
       "      <td>655.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 93 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   1stFlrSF  2ndFlrSF  3SsnPorch  Alley  BedroomAbvGr BldgType BsmtCond  \\\n",
       "0       856       854          0      0             3     1Fam       TA   \n",
       "1      1262         0          0      0             3     1Fam       TA   \n",
       "2       920       866          0      0             3     1Fam       TA   \n",
       "3       961       756          0      0             3     1Fam       Gd   \n",
       "4      1145      1053          0      0             4     1Fam       TA   \n",
       "\n",
       "  BsmtExposure  BsmtFinSF1  BsmtFinSF2       ...       Fence_MnPrv Fence_MnWw  \\\n",
       "0           No       706.0         0.0       ...                 0          0   \n",
       "1           Gd       978.0         0.0       ...                 0          0   \n",
       "2           Mn       486.0         0.0       ...                 0          0   \n",
       "3           No       216.0         0.0       ...                 0          0   \n",
       "4           Av       655.0         0.0       ...                 0          0   \n",
       "\n",
       "   Fence_None  GarageType_2Types GarageType_Attchd  GarageType_Basment  \\\n",
       "0           1                  0                 1                   0   \n",
       "1           1                  0                 1                   0   \n",
       "2           1                  0                 1                   0   \n",
       "3           1                  0                 0                   0   \n",
       "4           1                  0                 1                   0   \n",
       "\n",
       "  GarageType_BuiltIn GarageType_CarPort GarageType_Detchd GarageType_None  \n",
       "0                  0                  0                 0               0  \n",
       "1                  0                  0                 0               0  \n",
       "2                  0                  0                 0               0  \n",
       "3                  0                  0                 1               0  \n",
       "4                  0                  0                 0               0  \n",
       "\n",
       "[5 rows x 93 columns]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concated_dataset.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Those are just some numeric features mostly NA means 0.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ('GarageYrBlt', 'GarageArea', 'GarageCars'):\n",
    "    concated_dataset[col] = concated_dataset[col].fillna(0)\n",
    "for col in ('BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF','TotalBsmtSF', 'BsmtFullBath', 'BsmtHalfBath'):\n",
    "    concated_dataset[col] = concated_dataset[col].fillna(0)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Now lets investigate :'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2. First lets fill those up with None since NA is non Artithmatic and creates problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ('BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2'):\n",
    "    concated_dataset[col] = concated_dataset[col].fillna('None')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Now I will manually encode those feature to numeric. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "concated_dataset[\"BsmtQual\"] =concated_dataset[\"BsmtQual\"].replace(to_replace={\"Ex\": 5, \"Gd\":4,\"TA\":3,\"Fa\":2,\"Po\":1,\"None\":0})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "concated_dataset[\"BsmtCond\"] =concated_dataset[\"BsmtCond\"].replace(to_replace={\"Ex\": 5, \"Gd\":4,\"TA\":3,\"Fa\":2,\"Po\":1,\"None\":0})\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Lets check if our manual encoding is working.Instead we could have just used label encoder but my guess is that  prior knowledge injection though manual encoding will work slightly better. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Lets talk about basement exposer. BsmtExposure: Refers to walkout or garden level walls\n",
    "\n",
    "       Gd\tGood Exposure\n",
    "       Av\tAverage Exposure (split levels or foyers typically score average or above)\t\n",
    "       Mn\tMimimum Exposure\n",
    "       No\tNo Exposure\n",
    "       NA\tNo Basement\n",
    " I think No basement and no exposer should both have numerial weight 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "concated_dataset[\"BsmtExposure\"] =concated_dataset[\"BsmtExposure\"].replace(to_replace={\"Gd\":3,\"Av\":2,\"Mn\":1,\"No\":0,\"None\":0})\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "BsmtFinType1: Rating of basement finished area\n",
    "       GLQ\tGood Living Quarters\n",
    "       ALQ\tAverage Living Quarters\n",
    "       BLQ\tBelow Average Living Quarters\t\n",
    "       Rec\tAverage Rec Room\n",
    "       LwQ\tLow Quality\n",
    "       Unf\tUnfinshed\n",
    "       NA\tNo Basement\n",
    "Lets manually encode this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "concated_dataset[\"BsmtFinType1\"] =concated_dataset[\"BsmtFinType1\"].replace(to_replace={\"GLQ\":6,\"ALQ\":5,\"BLQ\":4,\"Rec\":3,\"LwQ\":2,\"Unf\":1,\"None\":0})\n",
    "concated_dataset[\"BsmtFinType2\"] =concated_dataset[\"BsmtFinType2\"].replace(to_replace={\"GLQ\":6,\"ALQ\":5,\"BLQ\":4,\"Rec\":3,\"LwQ\":2,\"Unf\":1,\"None\":0})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       6\n",
      "1       5\n",
      "2       6\n",
      "3       5\n",
      "4       6\n",
      "5       6\n",
      "6       6\n",
      "7       5\n",
      "8       1\n",
      "9       6\n",
      "10      3\n",
      "11      6\n",
      "12      5\n",
      "13      1\n",
      "14      4\n",
      "15      1\n",
      "16      5\n",
      "17      0\n",
      "18      6\n",
      "19      2\n",
      "20      1\n",
      "21      1\n",
      "22      1\n",
      "23      6\n",
      "24      3\n",
      "25      1\n",
      "26      4\n",
      "27      6\n",
      "28      4\n",
      "29      1\n",
      "       ..\n",
      "1429    1\n",
      "1430    1\n",
      "1431    0\n",
      "1432    1\n",
      "1433    1\n",
      "1434    6\n",
      "1435    6\n",
      "1436    6\n",
      "1437    1\n",
      "1438    1\n",
      "1439    6\n",
      "1440    4\n",
      "1441    6\n",
      "1442    6\n",
      "1443    6\n",
      "1444    0\n",
      "1445    6\n",
      "1446    1\n",
      "1447    5\n",
      "1448    4\n",
      "1449    6\n",
      "1450    3\n",
      "1451    3\n",
      "1452    3\n",
      "1453    1\n",
      "1454    1\n",
      "1455    3\n",
      "1456    5\n",
      "1457    6\n",
      "1458    2\n",
      "Name: BsmtFinType1, Length: 2919, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(concated_dataset[\"BsmtFinType1\"])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "MasVnrType: Masonry veneer type\n",
    "\n",
    "       BrkCmn\tBrick Common\n",
    "       BrkFace\tBrick Face\n",
    "       CBlock\tCinder Block\n",
    "       None\tNone\n",
    "       Stone\tStone\n",
    " I will one hot encode this.\n",
    " MasVnrArea: Masonry veneer area in square feet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "concated_dataset[\"MasVnrType\"] = concated_dataset[\"MasVnrType\"].fillna(\"None\")\n",
    "concated_dataset[\"MasVnrArea\"] = concated_dataset[\"MasVnrArea\"].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "concated_dataset[\"MasVnrType\"]=pd.Categorical(concated_dataset[\"MasVnrType\"])\n",
    "dfDummies_MasVnrType = pd.get_dummies(concated_dataset[\"MasVnrType\"], prefix = 'MasVnrType')\n",
    "concated_dataset = pd.concat([concated_dataset, dfDummies_MasVnrType], axis=1)\n",
    "concated_dataset = concated_dataset.drop(['MasVnrType'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['BldgType', 'CentralAir', 'Condition1', 'Condition2', 'Electrical',\n",
       "       'ExterCond', 'ExterQual', 'Exterior1st', 'Exterior2nd', 'Foundation',\n",
       "       'Functional', 'Heating', 'HeatingQC', 'HouseStyle', 'KitchenQual',\n",
       "       'LandContour', 'LandSlope', 'LotConfig', 'LotShape', 'MSZoning',\n",
       "       'Neighborhood', 'PavedDrive', 'RoofMatl', 'RoofStyle', 'SaleCondition',\n",
       "       'SaleType', 'Street', 'Utilities'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concated_dataset.select_dtypes(include=['object']).columns\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "MSZoning: Identifies the general zoning classification of the sale.\n",
    "\t\t\n",
    "       A\tAgriculture\n",
    "       C\tCommercial\n",
    "       FV\tFloating Village Residential\n",
    "       I\tIndustrial\n",
    "       RH\tResidential High Density\n",
    "       RL\tResidential Low Density\n",
    "       RP\tResidential Low Density Park \n",
    "       RM\tResidential Medium Density\n",
    "All the house should have one of the above.If not given we can probably the most common one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "concated_dataset['MSZoning'] = concated_dataset['MSZoning'].fillna(concated_dataset['MSZoning'].mode()[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "concated_dataset[\"MSZoning\"]=pd.Categorical(concated_dataset[\"MSZoning\"])\n",
    "dfDummies_MSZoning = pd.get_dummies(concated_dataset[\"MSZoning\"], prefix = 'MSZoning')\n",
    "concated_dataset = pd.concat([concated_dataset, dfDummies_MSZoning], axis=1)\n",
    "concated_dataset = concated_dataset.drop(['MSZoning'], axis=1)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\t\t\n",
    "Utilities: Type of utilities available\n",
    "\t\t\n",
    "       AllPub\tAll public Utilities (E,G,W,& S)\t\n",
    "       NoSewr\tElectricity, Gas, and Water (Septic Tank)\n",
    "       NoSeWa\tElectricity and Gas Only\n",
    "       ELO\tElectricity only\n",
    "Need to one hot represent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "concated_dataset[\"Utilities\"] = concated_dataset[\"Utilities\"].fillna(\"None\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "concated_dataset[\"Utilities\"]=pd.Categorical(concated_dataset[\"Utilities\"])\n",
    "dfDummies_Utilities = pd.get_dummies(concated_dataset[\"Utilities\"], prefix = 'Utilities')\n",
    "concated_dataset = pd.concat([concated_dataset, dfDummies_Utilities], axis=1)\n",
    "concated_dataset = concated_dataset.drop(['Utilities'], axis=1)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Functional: Home functionality (Assume typical unless deductions are warranted)\n",
    "\n",
    "       Typ\tTypical Functionality\n",
    "       Min1\tMinor Deductions 1\n",
    "       Min2\tMinor Deductions 2\n",
    "       Mod\tModerate Deductions\n",
    "       Maj1\tMajor Deductions 1\n",
    "       Maj2\tMajor Deductions 2\n",
    "       Sev\tSeverely Damaged\n",
    "       Sal\tSalvage only\n",
    "Functional : data description says NA means typical. Again we will impose prior. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "concated_dataset[\"Functional\"] = concated_dataset[\"Functional\"].fillna(\"Typ\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "concated_dataset[\"Functional\"] =concated_dataset[\"Functional\"].replace(to_replace={\"Typ\": 8, \"Min1\":7,\"Min2\":6,\"Mod\":5,\"Maj1\":4,\"Maj2\":3,\"Sev\":2,\"Sal\":1})\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Electrical: Electrical system\n",
    "\n",
    "       SBrkr\tStandard Circuit Breakers & Romex\n",
    "       FuseA\tFuse Box over 60 AMP and all Romex wiring (Average)\t\n",
    "       FuseF\t60 AMP Fuse Box and mostly Romex wiring (Fair)\n",
    "       FuseP\t60 AMP Fuse Box and mostly knob & tube wiring (poor)\n",
    "       Mix\tMixed\n",
    "Although I some ranking but Maxed is good or bad I don't know that.So label encode that too. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "concated_dataset['Electrical'] = concated_dataset['Electrical'].fillna(concated_dataset['Electrical'].mode()[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "concated_dataset[\"Electrical\"]=pd.Categorical(concated_dataset[\"Electrical\"])\n",
    "dfDummies_Electrical = pd.get_dummies(concated_dataset[\"Electrical\"], prefix = 'Electrical')\n",
    "concated_dataset = pd.concat([concated_dataset, dfDummies_Electrical], axis=1)\n",
    "concated_dataset = concated_dataset.drop(['Electrical'], axis=1)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "KitchenQual: Kitchen quality\n",
    "\n",
    "       Ex\tExcellent\n",
    "       Gd\tGood\n",
    "       TA\tTypical/Average\n",
    "       Fa\tFair\n",
    "       Po\tPoor\n",
    "Lets fill NA with the most common value. I woul have replaced NA with none if the feature was mostly sparse or not filled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "concated_dataset['KitchenQual'] = concated_dataset['KitchenQual'].fillna(concated_dataset['KitchenQual'].mode()[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "concated_dataset[\"KitchenQual\"] =concated_dataset[\"KitchenQual\"].replace(to_replace={\"Ex\": 5, \"Gd\":4,\"TA\":3,\"Fa\":2,\"Po\":1,\"None\":0})\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Exterior1st: Exterior covering on house\n",
    "       AsbShng\tAsbestos Shingles\n",
    "       AsphShn\tAsphalt Shingles\n",
    "       BrkComm\tBrick Common\n",
    "       BrkFace\tBrick Face\n",
    "       CBlock\tCinder Block\n",
    "       CemntBd\tCement Board\n",
    "       HdBoard\tHard Board\n",
    "       ImStucc\tImitation Stucco\n",
    "       MetalSd\tMetal Siding\n",
    "       Other\tOther\n",
    "       Plywood\tPlywood\n",
    "       PreCast\tPreCast\t\n",
    "       Stone\tStone\n",
    "       Stucco\tStucco\n",
    "       VinylSd\tVinyl Siding\n",
    "       Wd Sdng\tWood Siding\n",
    "       WdShing\tWood Shingles\n",
    "People with more domain knowledge will be able to give properraking while encode. Since I dont know that I will one hot encode this. There will be space for improvement for those who have domain knowledge.\n",
    "Exterior2nd: Exterior covering on house (if more than one material)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "concated_dataset['Exterior1st'] = concated_dataset['Exterior1st'].fillna(concated_dataset['Exterior1st'].mode()[0])\n",
    "concated_dataset['Exterior2nd'] = concated_dataset['Exterior2nd'].fillna(concated_dataset['Exterior2nd'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "concated_dataset[\"Exterior1st\"]=pd.Categorical(concated_dataset[\"Exterior1st\"])\n",
    "dfDummies_Exterior1st = pd.get_dummies(concated_dataset[\"Exterior1st\"], prefix = 'Exterior1st')\n",
    "concated_dataset = pd.concat([concated_dataset, dfDummies_Exterior1st], axis=1)\n",
    "concated_dataset = concated_dataset.drop(['Exterior1st'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "concated_dataset[\"Exterior2nd\"]=pd.Categorical(concated_dataset[\"Exterior2nd\"])\n",
    "dfDummies_Exterior2nd = pd.get_dummies(concated_dataset[\"Exterior2nd\"], prefix = 'Exterior2nd')\n",
    "concated_dataset = pd.concat([concated_dataset, dfDummies_Exterior2nd], axis=1)\n",
    "concated_dataset = concated_dataset.drop(['Exterior2nd'], axis=1)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "SaleType: Type of sale\n",
    "\t\t\n",
    "       WD \tWarranty Deed - Conventional\n",
    "       CWD\tWarranty Deed - Cash\n",
    "       VWD\tWarranty Deed - VA Loan\n",
    "       New\tHome just constructed and sold\n",
    "       COD\tCourt Officer Deed/Estate\n",
    "       Con\tContract 15% Down payment regular terms\n",
    "       ConLw\tContract Low Down payment and low interest\n",
    "       ConLI\tContract Low Interest\n",
    "       ConLD\tContract Low Down\n",
    "       Oth\tOther\n",
    "Need to one hot encode that due to lack of prior knowledge.First fill up missing value with the most common type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "concated_dataset['SaleType'] = concated_dataset['SaleType'].fillna(concated_dataset['SaleType'].mode()[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "concated_dataset[\"SaleType\"]=pd.Categorical(concated_dataset[\"SaleType\"])\n",
    "dfDummies_SaleType = pd.get_dummies(concated_dataset[\"SaleType\"], prefix = 'SaleType')\n",
    "concated_dataset = pd.concat([concated_dataset, dfDummies_SaleType], axis=1)\n",
    "concated_dataset = concated_dataset.drop(['SaleType'], axis=1)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "MSSubClass: Identifies the type of dwelling involved in the sale.\t\n",
    "\n",
    "        20\t1-STORY 1946 & NEWER ALL STYLES\n",
    "        30\t1-STORY 1945 & OLDER\n",
    "        40\t1-STORY W/FINISHED ATTIC ALL AGES\n",
    "        45\t1-1/2 STORY - UNFINISHED ALL AGES\n",
    "        50\t1-1/2 STORY FINISHED ALL AGES\n",
    "        60\t2-STORY 1946 & NEWER\n",
    "        70\t2-STORY 1945 & OLDER\n",
    "        75\t2-1/2 STORY ALL AGES\n",
    "        80\tSPLIT OR MULTI-LEVEL\n",
    "        85\tSPLIT FOYER\n",
    "        90\tDUPLEX - ALL STYLES AND AGES\n",
    "       120\t1-STORY PUD (Planned Unit Development) - 1946 & NEWER\n",
    "       150\t1-1/2 STORY PUD - ALL AGES\n",
    "       160\t2-STORY PUD - 1946 & NEWER\n",
    "       180\tPUD - MULTILEVEL - INCL SPLIT LEV/FOYER\n",
    "       190\t2 FAMILY CONVERSION - ALL STYLES AND AGES\n",
    "No idea. I will use one hot encode and fillup with common value but None can be used have to check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "concated_dataset['MSSubClass'] = concated_dataset['MSSubClass'].astype(str)\n",
    "concated_dataset['MSSubClass'] = concated_dataset['MSSubClass'].fillna(concated_dataset['MSSubClass'].mode()[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "concated_dataset[\"MSSubClass\"]=pd.Categorical(concated_dataset[\"MSSubClass\"])\n",
    "dfDummies_MSSubClass = pd.get_dummies(concated_dataset[\"MSSubClass\"], prefix = 'MSSubClass')\n",
    "concated_dataset = pd.concat([concated_dataset, dfDummies_MSSubClass], axis=1)\n",
    "concated_dataset = concated_dataset.drop(['MSSubClass'], axis=1)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ckeck for missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Missing Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Missing Ratio]\n",
       "Index: []"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data_na = (concated_dataset.isnull().sum() / len(concated_dataset)) * 100\n",
    "all_data_na = all_data_na.drop(all_data_na[all_data_na == 0].index).sort_values(ascending=False)[:30]\n",
    "missing_data = pd.DataFrame({'Missing Ratio' :all_data_na})\n",
    "missing_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['BldgType', 'CentralAir', 'Condition1', 'Condition2', 'ExterCond',\n",
       "       'ExterQual', 'Foundation', 'Heating', 'HeatingQC', 'HouseStyle',\n",
       "       'LandContour', 'LandSlope', 'LotConfig', 'LotShape', 'Neighborhood',\n",
       "       'PavedDrive', 'RoofMatl', 'RoofStyle', 'SaleCondition', 'Street'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concated_dataset.select_dtypes(include=['object']).columns\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Lets investigae BldgType.\n",
    "BldgType: Type of dwelling\n",
    "       1Fam\tSingle-family Detached\t\n",
    "       2FmCon\tTwo-family Conversion; originally built as one-family dwelling\n",
    "       Duplx\tDuplex\n",
    "       TwnhsE\tTownhouse End Unit\n",
    "       TwnhsI\tTownhouse Inside Unit\n",
    "One hot encode that since no knowledge of correlation with saleprice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "concated_dataset[\"BldgType\"]=pd.Categorical(concated_dataset[\"BldgType\"])\n",
    "dfDummies_BldgType = pd.get_dummies(concated_dataset[\"BldgType\"], prefix = 'BldgType')\n",
    "concated_dataset = pd.concat([concated_dataset, dfDummies_BldgType], axis=1)\n",
    "concated_dataset = concated_dataset.drop(['BldgType'], axis=1)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "CentralAir: Central air conditioning\n",
    "\n",
    "       N\tNo\n",
    "       Y\tYes\n",
    "I will manually encode that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "concated_dataset[\"CentralAir\"] =concated_dataset[\"CentralAir\"].replace(to_replace={\"N\": 5, \"Y\":4})\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Condition1: Proximity to various conditions\n",
    "       Artery\tAdjacent to arterial street\n",
    "       Feedr\tAdjacent to feeder street\t\n",
    "       Norm\tNormal\t\n",
    "       RRNn\tWithin 200' of North-South Railroad\n",
    "       RRAn\tAdjacent to North-South Railroad\n",
    "       PosN\tNear positive off-site feature--park, greenbelt, etc.\n",
    "       PosA\tAdjacent to postive off-site feature\n",
    "       RRNe\tWithin 200' of East-West Railroad\n",
    "       RRAe\tAdjacent to East-West Railroal\n",
    "Lets one hot encode that. Same for condition 2.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "concated_dataset[\"Condition1\"]=pd.Categorical(concated_dataset[\"Condition1\"])\n",
    "dfDummies_condition1 = pd.get_dummies(concated_dataset[\"Condition1\"], prefix = 'Condition1')\n",
    "concated_dataset = pd.concat([concated_dataset, dfDummies_condition1], axis=1)\n",
    "concated_dataset = concated_dataset.drop(['Condition1'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "concated_dataset[\"Condition2\"]=pd.Categorical(concated_dataset[\"Condition2\"])\n",
    "dfDummies_condition2 = pd.get_dummies(concated_dataset[\"Condition2\"], prefix = 'Condition2')\n",
    "concated_dataset = pd.concat([concated_dataset, dfDummies_condition2], axis=1)\n",
    "concated_dataset = concated_dataset.drop(['Condition2'], axis=1)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ExterCond: Evaluates the present condition of the material on the exterior\n",
    "\t\t\n",
    "       Ex\tExcellent\n",
    "       Gd\tGood\n",
    "       TA\tAverage/Typical\n",
    "       Fa\tFair\n",
    "       Po\tPoor\n",
    "Let's manually encode that.Same for ExterQual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "concated_dataset[\"ExterCond\"] =concated_dataset[\"ExterCond\"].replace(to_replace={\"Ex\": 5, \"Gd\":4,\"TA\":3,\"Fa\":2,\"Po\":1,\"None\":0})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "concated_dataset[\"ExterQual\"] =concated_dataset[\"ExterQual\"].replace(to_replace={\"Ex\": 5, \"Gd\":4,\"TA\":3,\"Fa\":2,\"Po\":1,\"None\":0})\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Foundation: Type of foundation\n",
    "\t\t\n",
    "       BrkTil\tBrick & Tile\n",
    "       CBlock\tCinder Block\n",
    "       PConc\tPoured Contrete\t\n",
    "       Slab\tSlab\n",
    "       Stone\tStone\n",
    "       Wood\tWood\n",
    "Correlation unknown.Using One hot encoding. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "concated_dataset[\"Foundation\"]=pd.Categorical(concated_dataset[\"Foundation\"])\n",
    "dfDummies_Foundation = pd.get_dummies(concated_dataset[\"Foundation\"], prefix = 'Foundation')\n",
    "concated_dataset = pd.concat([concated_dataset, dfDummies_Foundation], axis=1)\n",
    "concated_dataset = concated_dataset.drop(['Foundation'], axis=1)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Heating: Type of heating\n",
    "\t\t\n",
    "       Floor\tFloor Furnace\n",
    "       GasA\tGas forced warm air furnace\n",
    "       GasW\tGas hot water or steam heat\n",
    "       Grav\tGravity furnace\t\n",
    "       OthW\tHot water or steam heat other than gas\n",
    "       Wall\tWall furnace\n",
    "Correlation unknown.Using One hot encoding. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "concated_dataset[\"Heating\"]=pd.Categorical(concated_dataset[\"Heating\"])\n",
    "dfDummies_Heating = pd.get_dummies(concated_dataset[\"Heating\"], prefix = 'Heating')\n",
    "concated_dataset = pd.concat([concated_dataset, dfDummies_Heating], axis=1)\n",
    "concated_dataset = concated_dataset.drop(['Heating'], axis=1)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "HeatingQC: Heating quality and condition\n",
    "       Ex\tExcellent\n",
    "       Gd\tGood\n",
    "       TA\tAverage/Typical\n",
    "       Fa\tFair\n",
    "       Po\tPoor\n",
    "manual encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "concated_dataset[\"HeatingQC\"] =concated_dataset[\"HeatingQC\"].replace(to_replace={\"Ex\": 5, \"Gd\":4,\"TA\":3,\"Fa\":2,\"Po\":1})\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "HouseStyle: Style of dwelling       \n",
    "       1Story\tOne story\n",
    "       1.5Fin\tOne and one-half story: 2nd level finished\n",
    "       1.5Unf\tOne and one-half story: 2nd level unfinished\n",
    "       2Story\tTwo story\n",
    "       2.5Fin\tTwo and one-half story: 2nd level finished\n",
    "       2.5Unf\tTwo and one-half story: 2nd level unfinished\n",
    "       SFoyer\tSplit Foyer\n",
    "       SLvl\tSplit Level\n",
    "We dont know for sure which is better. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "concated_dataset[\"HouseStyle\"]=pd.Categorical(concated_dataset[\"HouseStyle\"])\n",
    "dfDummies_HouseStyle = pd.get_dummies(concated_dataset[\"HouseStyle\"], prefix = 'HouseStyle')\n",
    "concated_dataset = pd.concat([concated_dataset, dfDummies_HouseStyle], axis=1)\n",
    "concated_dataset = concated_dataset.drop(['HouseStyle'], axis=1)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "LandContour: Flatness of the property\n",
    "       Lvl\tNear Flat/Level\t\n",
    "       Bnk\tBanked - Quick and significant rise from street grade to building\n",
    "       HLS\tHillside - Significant slope from side to side\n",
    "       Low\tDepression\n",
    "Using one hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "concated_dataset[\"LandContour\"]=pd.Categorical(concated_dataset[\"LandContour\"])\n",
    "dfDummies_LandContour = pd.get_dummies(concated_dataset[\"LandContour\"], prefix = 'LandContour')\n",
    "concated_dataset = pd.concat([concated_dataset, dfDummies_LandContour], axis=1)\n",
    "concated_dataset = concated_dataset.drop(['LandContour'], axis=1)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "LandSlope: Slope of property\n",
    "       Gtl\tGentle slope\n",
    "       Mod\tModerate Slope\t\n",
    "       Sev\tSevere Slope\n",
    "Using one hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "concated_dataset[\"LandSlope\"]=pd.Categorical(concated_dataset[\"LandSlope\"])\n",
    "dfDummies_LandSlope = pd.get_dummies(concated_dataset[\"LandSlope\"], prefix = 'LandSlope')\n",
    "concated_dataset = pd.concat([concated_dataset, dfDummies_LandSlope], axis=1)\n",
    "concated_dataset = concated_dataset.drop(['LandSlope'], axis=1)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "LotConfig: Lot configuration\n",
    "       Inside\tInside lot\n",
    "       Corner\tCorner lot\n",
    "       CulDSac\tCul-de-sac\n",
    "       FR2\tFrontage on 2 sides of property\n",
    "       FR3\tFrontage on 3 sides of property\n",
    "Using one hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "concated_dataset[\"LotConfig\"]=pd.Categorical(concated_dataset[\"LotConfig\"])\n",
    "dfDummies_LotConfig = pd.get_dummies(concated_dataset[\"LotConfig\"], prefix = 'LotConfig')\n",
    "concated_dataset = pd.concat([concated_dataset, dfDummies_LotConfig], axis=1)\n",
    "concated_dataset = concated_dataset.drop(['LotConfig'], axis=1)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "LotShape: General shape of property\n",
    "       Reg\tRegular\t\n",
    "       IR1\tSlightly irregular\n",
    "       IR2\tModerately Irregular\n",
    "       IR3\tIrregular\n",
    "Does general shape better then Irregular.Not always may be fency Irregular shape is more costly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "concated_dataset[\"LotShape\"]=pd.Categorical(concated_dataset[\"LotShape\"])\n",
    "dfDummies_LotShape = pd.get_dummies(concated_dataset[\"LotShape\"], prefix = 'LotShape')\n",
    "concated_dataset = pd.concat([concated_dataset, dfDummies_LotShape], axis=1)\n",
    "concated_dataset = concated_dataset.drop(['LotShape'], axis=1)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Neighborhood: Physical locations within Ames city limits\n",
    "\n",
    "       Blmngtn\tBloomington Heights\n",
    "       Blueste\tBluestem\n",
    "       BrDale\tBriardale\n",
    "       BrkSide\tBrookside\n",
    "       ClearCr\tClear Creek\n",
    "       CollgCr\tCollege Creek\n",
    "       Crawfor\tCrawford\n",
    "       Edwards\tEdwards\n",
    "       Gilbert\tGilbert\n",
    "       IDOTRR\tIowa DOT and Rail Road\n",
    "       MeadowV\tMeadow Village\n",
    "       Mitchel\tMitchell\n",
    "       Names\tNorth Ames\n",
    "       NoRidge\tNorthridge\n",
    "       NPkVill\tNorthpark Villa\n",
    "       NridgHt\tNorthridge Heights\n",
    "       NWAmes\tNorthwest Ames\n",
    "       OldTown\tOld Town\n",
    "       SWISU\tSouth & West of Iowa State University\n",
    "       Sawyer\tSawyer\n",
    "       SawyerW\tSawyer West\n",
    "       Somerst\tSomerset\n",
    "       StoneBr\tStone Brook\n",
    "       Timber\tTimberland\n",
    "       Veenker\tVeenker\n",
    "People with domain knowledge could have used maula encoding. I am doing one hot encoding. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "concated_dataset[\"Neighborhood\"]=pd.Categorical(concated_dataset[\"Neighborhood\"])\n",
    "dfDummies_Neighborhood = pd.get_dummies(concated_dataset[\"Neighborhood\"], prefix = 'Neighborhood')\n",
    "concated_dataset = pd.concat([concated_dataset, dfDummies_Neighborhood], axis=1)\n",
    "concated_dataset = concated_dataset.drop(['Neighborhood'], axis=1)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "PavedDrive: Paved driveway\n",
    "\n",
    "       Y\tPaved \n",
    "       P\tPartial Pavement\n",
    "       N\tDirt/Gravel\n",
    "I think I know some correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "concated_dataset[\"PavedDrive\"]=pd.Categorical(concated_dataset[\"PavedDrive\"])\n",
    "dfDummies_PavedDrive = pd.get_dummies(concated_dataset[\"PavedDrive\"], prefix = 'PavedDrive')\n",
    "concated_dataset = pd.concat([concated_dataset, dfDummies_PavedDrive], axis=1)\n",
    "concated_dataset = concated_dataset.drop(['PavedDrive'], axis=1)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "RoofMatl: Roof material\n",
    "       ClyTile\tClay or Tile\n",
    "       CompShg\tStandard (Composite) Shingle\n",
    "       Membran\tMembrane\n",
    "       Metal\tMetal\n",
    "       Roll\tRoll\n",
    "       Tar&Grv\tGravel & Tar\n",
    "       WdShake\tWood Shakes\n",
    "       WdShngl\tWood Shingles\n",
    "One hot encode that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "concated_dataset[\"RoofMatl\"]=pd.Categorical(concated_dataset[\"RoofMatl\"])\n",
    "dfDummies_RoofMatl = pd.get_dummies(concated_dataset[\"RoofMatl\"], prefix = 'RoofMatl')\n",
    "concated_dataset = pd.concat([concated_dataset, dfDummies_RoofMatl], axis=1)\n",
    "concated_dataset = concated_dataset.drop(['RoofMatl'], axis=1)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "RoofStyle: Type of roof\n",
    "       Flat\tFlat\n",
    "       Gable\tGable\n",
    "       Gambrel\tGabrel (Barn)\n",
    "       Hip\tHip\n",
    "       Mansard\tMansard\n",
    "       Shed\tShed\n",
    "One hot encode that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "concated_dataset[\"RoofStyle\"]=pd.Categorical(concated_dataset[\"RoofStyle\"])\n",
    "dfDummies_RoofStyle = pd.get_dummies(concated_dataset[\"RoofStyle\"], prefix = 'RoofStyle')\n",
    "concated_dataset = pd.concat([concated_dataset, dfDummies_RoofStyle], axis=1)\n",
    "concated_dataset = concated_dataset.drop(['RoofStyle'], axis=1)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "SaleCondition: Condition of sale\n",
    "\n",
    "       Normal\tNormal Sale\n",
    "       Abnorml\tAbnormal Sale -  trade, foreclosure, short sale\n",
    "       AdjLand\tAdjoining Land Purchase\n",
    "       Alloca\tAllocation - two linked properties with separate deeds, typically condo with a garage unit\t\n",
    "       Family\tSale between family members\n",
    "       Partial\tHome was not completed when last assessed (associated with New Homes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "concated_dataset[\"SaleCondition\"]=pd.Categorical(concated_dataset[\"SaleCondition\"])\n",
    "dfDummies_SaleCondition = pd.get_dummies(concated_dataset[\"SaleCondition\"], prefix = 'SaleCondition')\n",
    "concated_dataset = pd.concat([concated_dataset, dfDummies_SaleCondition], axis=1)\n",
    "concated_dataset = concated_dataset.drop(['SaleCondition'], axis=1)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Street: Type of road access to property\n",
    "\n",
    "       Grvl\tGravel\t\n",
    "       Pave\tPaved\n",
    "I dont knwo the correlation.We want to learn that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "concated_dataset[\"Street\"]=pd.Categorical(concated_dataset[\"Street\"])\n",
    "dfDummies_Street = pd.get_dummies(concated_dataset[\"Street\"], prefix = 'Street')\n",
    "concated_dataset = pd.concat([concated_dataset, dfDummies_Street], axis=1)\n",
    "concated_dataset = concated_dataset.drop(['Street'], axis=1)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "There are two more catagorail data in Numerial representation. YrSold and MoSold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "concated_dataset['YrSold'] = concated_dataset['YrSold'].astype(str)\n",
    "concated_dataset['MoSold'] = concated_dataset['MoSold'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "concated_dataset[\"YrSold\"]=pd.Categorical(concated_dataset[\"YrSold\"])\n",
    "dfDummies_YrSold = pd.get_dummies(concated_dataset[\"YrSold\"], prefix = 'YrSold')\n",
    "concated_dataset = pd.concat([concated_dataset, dfDummies_YrSold], axis=1)\n",
    "concated_dataset = concated_dataset.drop(['YrSold'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "concated_dataset[\"MoSold\"]=pd.Categorical(concated_dataset[\"MoSold\"])\n",
    "dfDummies_MoSold = pd.get_dummies(concated_dataset[\"MoSold\"], prefix = 'MoSold')\n",
    "concated_dataset = pd.concat([concated_dataset, dfDummies_MoSold], axis=1)\n",
    "concated_dataset = concated_dataset.drop(['MoSold'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>Alley</th>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <th>BsmtCond</th>\n",
       "      <th>BsmtExposure</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>BsmtFinType1</th>\n",
       "      <th>...</th>\n",
       "      <th>MoSold_11</th>\n",
       "      <th>MoSold_12</th>\n",
       "      <th>MoSold_2</th>\n",
       "      <th>MoSold_3</th>\n",
       "      <th>MoSold_4</th>\n",
       "      <th>MoSold_5</th>\n",
       "      <th>MoSold_6</th>\n",
       "      <th>MoSold_7</th>\n",
       "      <th>MoSold_8</th>\n",
       "      <th>MoSold_9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>856</td>\n",
       "      <td>854</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>706.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1262</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>978.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>920</td>\n",
       "      <td>866</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>486.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>961</td>\n",
       "      <td>756</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>216.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1145</td>\n",
       "      <td>1053</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>655.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 265 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   1stFlrSF  2ndFlrSF  3SsnPorch  Alley  BedroomAbvGr  BsmtCond  BsmtExposure  \\\n",
       "0       856       854          0      0             3         3             0   \n",
       "1      1262         0          0      0             3         3             3   \n",
       "2       920       866          0      0             3         3             1   \n",
       "3       961       756          0      0             3         4             0   \n",
       "4      1145      1053          0      0             4         3             2   \n",
       "\n",
       "   BsmtFinSF1  BsmtFinSF2  BsmtFinType1    ...     MoSold_11  MoSold_12  \\\n",
       "0       706.0         0.0             6    ...             0          0   \n",
       "1       978.0         0.0             5    ...             0          0   \n",
       "2       486.0         0.0             6    ...             0          0   \n",
       "3       216.0         0.0             5    ...             0          0   \n",
       "4       655.0         0.0             6    ...             0          1   \n",
       "\n",
       "   MoSold_2  MoSold_3  MoSold_4  MoSold_5  MoSold_6  MoSold_7  MoSold_8  \\\n",
       "0         1         0         0         0         0         0         0   \n",
       "1         0         0         0         1         0         0         0   \n",
       "2         0         0         0         0         0         0         0   \n",
       "3         1         0         0         0         0         0         0   \n",
       "4         0         0         0         0         0         0         0   \n",
       "\n",
       "   MoSold_9  \n",
       "0         0  \n",
       "1         0  \n",
       "2         1  \n",
       "3         0  \n",
       "4         0  \n",
       "\n",
       "[5 rows x 265 columns]"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concated_dataset.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "checking for catagorial values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([], dtype='object')"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concated_dataset.select_dtypes(include=['object']).columns\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Lets try to help our model by adding new feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "concated_dataset['TotalSF'] = concated_dataset['TotalBsmtSF'] + concated_dataset['1stFlrSF'] + concated_dataset['2ndFlrSF']"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Lets findout how to scale and normalize the data. first lets figure out whats the scewness"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "We should now use standard scaler to make the data easily trainable by neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import skew\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Skewed Features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MSSubClass_150</th>\n",
       "      <td>54.000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Exterior1st_ImStucc</th>\n",
       "      <td>54.000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RoofMatl_Membran</th>\n",
       "      <td>54.000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Condition2_RRAn</th>\n",
       "      <td>54.000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MiscFeature_TenC</th>\n",
       "      <td>54.000003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Skewed Features\n",
       "MSSubClass_150             54.000003\n",
       "Exterior1st_ImStucc        54.000003\n",
       "RoofMatl_Membran           54.000003\n",
       "Condition2_RRAn            54.000003\n",
       "MiscFeature_TenC           54.000003"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_feats = concated_dataset.dtypes[concated_dataset.dtypes != \"object\"].index\n",
    "\n",
    "# Check the skew of all numerical features\n",
    "skewed_feats = concated_dataset[numeric_feats].apply(lambda x: skew(x.dropna())).sort_values(ascending=False)\n",
    "skewness = pd.DataFrame({'Skewed Features' :skewed_feats})\n",
    "skewness.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 266 skewed numerical features to Box Cox transform\n"
     ]
    }
   ],
   "source": [
    "skewness = skewness[abs(skewness) > 0.75]\n",
    "print(\"There are {} skewed numerical features to Box Cox transform\".format(skewness.shape[0]))\n",
    "\n",
    "from scipy.special import boxcox1p\n",
    "skewed_features = skewness.index\n",
    "lam = 0.15\n",
    "for feat in skewed_features:\n",
    "    concated_dataset[feat] = boxcox1p(concated_dataset[feat], lam)\n",
    "    concated_dataset[feat] += 1"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "concated_dataset = pd.get_dummies(concated_dataset)\n",
    "print(concated_dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>Alley</th>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <th>BsmtCond</th>\n",
       "      <th>BsmtExposure</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>BsmtFinType1</th>\n",
       "      <th>...</th>\n",
       "      <th>MoSold_12</th>\n",
       "      <th>MoSold_2</th>\n",
       "      <th>MoSold_3</th>\n",
       "      <th>MoSold_4</th>\n",
       "      <th>MoSold_5</th>\n",
       "      <th>MoSold_6</th>\n",
       "      <th>MoSold_7</th>\n",
       "      <th>MoSold_8</th>\n",
       "      <th>MoSold_9</th>\n",
       "      <th>TotalSF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12.692623</td>\n",
       "      <td>12.686189</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.540963</td>\n",
       "      <td>2.540963</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>12.170327</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.259674</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.730463</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>15.976591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.792276</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.540963</td>\n",
       "      <td>2.540963</td>\n",
       "      <td>2.540963</td>\n",
       "      <td>13.062832</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.055642</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.730463</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>15.923100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.892039</td>\n",
       "      <td>12.724598</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.540963</td>\n",
       "      <td>2.540963</td>\n",
       "      <td>1.730463</td>\n",
       "      <td>11.200343</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.259674</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.730463</td>\n",
       "      <td>16.149678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13.013683</td>\n",
       "      <td>12.354094</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.540963</td>\n",
       "      <td>2.820334</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.274266</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.055642</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.730463</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>15.857121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.510588</td>\n",
       "      <td>13.271365</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.820334</td>\n",
       "      <td>2.540963</td>\n",
       "      <td>2.194318</td>\n",
       "      <td>11.971129</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.259674</td>\n",
       "      <td>...</td>\n",
       "      <td>1.730463</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>16.852312</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 266 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    1stFlrSF   2ndFlrSF  3SsnPorch  Alley  BedroomAbvGr  BsmtCond  \\\n",
       "0  12.692623  12.686189        1.0    1.0      2.540963  2.540963   \n",
       "1  13.792276   1.000000        1.0    1.0      2.540963  2.540963   \n",
       "2  12.892039  12.724598        1.0    1.0      2.540963  2.540963   \n",
       "3  13.013683  12.354094        1.0    1.0      2.540963  2.820334   \n",
       "4  13.510588  13.271365        1.0    1.0      2.820334  2.540963   \n",
       "\n",
       "   BsmtExposure  BsmtFinSF1  BsmtFinSF2  BsmtFinType1    ...      MoSold_12  \\\n",
       "0      1.000000   12.170327         1.0      3.259674    ...       1.000000   \n",
       "1      2.540963   13.062832         1.0      3.055642    ...       1.000000   \n",
       "2      1.730463   11.200343         1.0      3.259674    ...       1.000000   \n",
       "3      1.000000    9.274266         1.0      3.055642    ...       1.000000   \n",
       "4      2.194318   11.971129         1.0      3.259674    ...       1.730463   \n",
       "\n",
       "   MoSold_2  MoSold_3  MoSold_4  MoSold_5  MoSold_6  MoSold_7  MoSold_8  \\\n",
       "0  1.730463       1.0       1.0  1.000000       1.0       1.0       1.0   \n",
       "1  1.000000       1.0       1.0  1.730463       1.0       1.0       1.0   \n",
       "2  1.000000       1.0       1.0  1.000000       1.0       1.0       1.0   \n",
       "3  1.730463       1.0       1.0  1.000000       1.0       1.0       1.0   \n",
       "4  1.000000       1.0       1.0  1.000000       1.0       1.0       1.0   \n",
       "\n",
       "   MoSold_9    TotalSF  \n",
       "0  1.000000  15.976591  \n",
       "1  1.000000  15.923100  \n",
       "2  1.730463  16.149678  \n",
       "3  1.000000  15.857121  \n",
       "4  1.000000  16.852312  \n",
       "\n",
       "[5 rows x 266 columns]"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concated_dataset.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "We should now use standard scaler to make the data easily trainable by neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaled_features_cn = StandardScaler().fit_transform(concated_dataset.values)\n",
    "scaled_features_train_postprocess= pd.DataFrame(scaled_features_cn, index=concated_dataset.index, columns=concated_dataset.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Lets split the data.Where the belongs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_postprocess = concated_dataset[:train_index]\n",
    "test_postprocess = concated_dataset[test_index+1:]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "We should now use standard scaler to make the data easily trainable by neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_postprocess.values.astype(np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 266)"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "y_train = train_raw_labels.astype(np.float32)\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=train_labels.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1459, 266)"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test = test_postprocess.values.astype(np.float32)\n",
    "x_test.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Training with Tensorflow (normal regression) manual gradent computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 MSe = 39034880000.0\n",
      "Epoch 100 MSe = nan\n",
      "Epoch 200 MSe = nan\n",
      "Epoch 300 MSe = nan\n",
      "Epoch 400 MSe = nan\n"
     ]
    }
   ],
   "source": [
    "m,n=x_train.shape\n",
    "\n",
    "epochs=500\n",
    "learning_rate=0.01\n",
    "\n",
    "from numpy import c_\n",
    "x_train_bised=np.c_[np.ones((m,1)),x_train]\n",
    "X_tf_train=tf.constant(x_train_bised,dtype=tf.float32,name=\"X_tf_train\")\n",
    "\n",
    "\n",
    "y_tf_train=tf.constant(y_train.reshape(-1,1),dtype=tf.float32,name=\"y_tf_train\")\n",
    "weight=tf.Variable(tf.random_uniform([n+1,1],-1.0,1.0),name=\"weight\")\n",
    "\n",
    "\n",
    "y_pred_train=tf.matmul(X_tf_train,weight,name=\"y_pred_train\")\n",
    "\n",
    "loss=y_pred_train-y_tf_train\n",
    "mse=tf.reduce_mean(tf.square(loss),name=\"mse\")\n",
    "gradient=2/m*tf.matmul(tf.transpose(X_tf_train),loss)\n",
    "\n",
    "\n",
    "\n",
    "training=tf.assign(weight,weight-learning_rate*gradient)\n",
    "\n",
    "init=tf.global_variables_initializer()\n",
    "\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(epochs):\n",
    "        if epoch % 100 == 0:\n",
    "            print(\"Epoch\",epoch,\"MSe =\",mse.eval())\n",
    "        sess.run(training)\n",
    "    best_weight=weight.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"X_tf_train_1:0\", shape=(1460, 267), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(X_tf_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "house_data_plus_bias=np.c_[np.ones((m1,1)),housing.data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
